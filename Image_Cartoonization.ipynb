{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image Cartoonization.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jku2S5Juj9wH"
      },
      "source": [
        "import matplotlib.image as img\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.color import rgb2gray\n",
        "import numpy as np \n",
        "from PIL import Image\n",
        "import PIL\n",
        "import imageio\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAq2Yk2TfS8J"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "    # Edge Detection Kernels\n",
        "    Kx = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n",
        "    Ky = np.array([[1, 2, 1], [0, 0, 0], [-1, -2, -1]])\n",
        "\n",
        "    # Take gradients for both x and y axes\n",
        "    gradient_x = convolution(smoothed_image, Kx)\n",
        "    gradient_y = convolution(smoothed_image, Ky)\n",
        "\n",
        "    # Calculate gradient magnitude matrix\n",
        "    gradient_magnitude = np.sqrt(gradient_x**2+ gradient_y**2)\n",
        "\n",
        "    # Calculate gradient direction matrix\n",
        "    gradient_direction = np.arctan2(gradient_y, gradient_x) * 180 / np.pi\n",
        "\n",
        "    # Replace the negative pi angle values with their absolute value\n",
        "    gradient_direction[gradient_direction < 0] += 180\n",
        "\n",
        "    suppressed_image = non_maximum_suppression(gradient_magnitude, gradient_direction)\n",
        "    \n",
        "    thresholded_image = double_thresholding(suppressed_image)\n",
        "    \n",
        "    canny_edge_image = hysteresis(thresholded_image)\n",
        "    \n",
        "     \"\"\"\n",
        "   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFhsfOuFWlab"
      },
      "source": [
        "def convolution(image, kernel):\n",
        "    # Flip the kernel\n",
        "    kernel = np.flip(kernel,0)\n",
        "    kernel = np.flip(kernel,1)\n",
        "\n",
        "    # Determine output image matrix size. Subtract Kernel Size and add 1 to the original image\n",
        "    output_image_column_number = image.shape[0] - kernel.shape[0] + 1\n",
        "    output_image_row_number    = image.shape[1] - kernel.shape[1] + 1\n",
        "\n",
        "    #create output image matrix\n",
        "    output_image = np.zeros((output_image_column_number, output_image_row_number))\n",
        "\n",
        "    for y in range( output_image_row_number):\n",
        "        for x in range( output_image_column_number):     \n",
        "          list = kernel * image[x: x + kernel.shape[1], y: y +  kernel.shape[0]]\n",
        "          output_image[x, y] = list.sum() \n",
        "          \n",
        "\n",
        "    return output_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5SZMR0wfSNH"
      },
      "source": [
        "def showImage(image, title='Image', cmap_type = \"gray\") :\n",
        "  plt.imshow(image, cmap = cmap_type)\n",
        "  plt.axis('off')\n",
        "  plt.title(title)\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yPsIzxQgpqJ"
      },
      "source": [
        "def read_image_grayscale_maybe():\n",
        "    # Convert to Grayscale Image\n",
        "    image_np_array = np.array(Image.open(\"sample.jpg\").convert('L'))\n",
        "    #image_np_array = np.array(Image.open(\"sample.jpg\"))\n",
        "    image_Image = Image.open(\"sample.jpg\").convert('L')\n",
        "    return image_np_array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdKHgQ5bgh5R"
      },
      "source": [
        "# 3 farklı save\n",
        "\n",
        "imageio.imwrite('bilatereal_filtered_image.png', bilatereal_filtered_image)\n",
        "\n",
        "cv2.imwrite('bilatereal_filtered_image.png', bilatereal_filtered_image) \n",
        "\n",
        "quantized_image_8 = quantized_image_8.save(\"quantized_image_8.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K70rtsATh8fN"
      },
      "source": [
        "#prewitt edge detection part\n",
        "import cv2 as cv\n",
        "def canny_edge_detection(img):\n",
        "  edges = cv.Canny(img,100,200)\n",
        "  #imageio.imwrite('canny_edge.png', edges)\n",
        "  return edges"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcj9qBx-hpg9"
      },
      "source": [
        "#canny edge detection part\n",
        "import cv2 as cv\n",
        "def canny_edge_detection(img):\n",
        "  edges = cv.Canny(img,100,200)\n",
        "  #imageio.imwrite('canny_edge.png', edges)\n",
        "  return edges"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sP_Yz7xagGZa"
      },
      "source": [
        "#bilateral filtering part\n",
        "#np array alıyor\n",
        "def bilateral_filter(img):\n",
        "  bilatereal_filtered_image = cv2.bilateralFilter(img, 9,75,75)\n",
        "  #imageio.imwrite('bilatereal_filtered_image.png', bilatereal_filtered_image)\n",
        "  return bilatereal_filtered_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vns0D7eMfqi4"
      },
      "source": [
        "#quantization part\n",
        "#image image open alıyor img\n",
        "def quantize(img, group): #256, #128\n",
        "  quantized_image = img.quantize(group) \n",
        "  #imageio.imwrite('quantized.png', quantized_image)\n",
        "  return quantized_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYKx8e9nYCHa"
      },
      "source": [
        "#median smoothing part\n",
        "def median_smoothing(img):\n",
        "  median_blurred_image  = cv2.medianBlur(img ,5)\n",
        "  #wimageio.imwrite('median_blurred_image.png', median_blurred_image)\n",
        "  return median_blurred_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmM_8atdXiLp"
      },
      "source": [
        "#box blurring part\n",
        "def box_blur_smoothing(img):\n",
        "  # Box Blur Kernel\n",
        "  box_blur_kernel =  np.array(\n",
        "      [[1/9,1/9,1/9,1/9,1/9],\n",
        "       [1/9,1/9,1/9,1/9,1/9],\n",
        "       [1/9,1/9,1/9,1/9,1/9],\n",
        "       [1/9,1/9,1/9,1/9,1/9],\n",
        "       [1/9,1/9,1/9,1/9,1/9]], dtype=\"int\")                         #deneysel\n",
        "  box_blurred_image = convolution(img, box_blur_kernel)\n",
        "  #imageio.imwrite('box_blurred_image.png', box_blurred_image)\n",
        "  return box_blurred_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGJsQ3KjW6bZ"
      },
      "source": [
        "#gaussian smoothing part\n",
        "def gaussian_smoothing(img):\n",
        "  # Gaussian Kernel\n",
        "  gaussian_kernel = np.array(\n",
        "      [[1/16,1/8,1/16],\n",
        "       [1/8,1/4,1/8],\n",
        "       [1/16,1/8,1/16]], dtype=\"int\")                         #deneysel\n",
        "  gauss_blurred_image = convolution(img, gaussian_kernel)\n",
        "  #imageio.imwrite('gauss_blurred_image.png', gauss_blurred_image)\n",
        "  return gauss_blurred_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAm4_GqUNeLG"
      },
      "source": [
        "#hit or miss transform part\n",
        "import cv2 as cv \n",
        "def hit_or_miss_transform(image):\n",
        "  #input_image = np.array(Image.open(\"a.jpg\").convert('L'))\n",
        "  kernel = np.array((\n",
        "        [0, 1, 0],\n",
        "        [1, -1, 1],\n",
        "        [0, 1, 0]), dtype=\"int\")\n",
        "\n",
        "  output_image = cv.morphologyEx(image, cv.MORPH_HITMISS, kernel)\n",
        "\n",
        "  rate = 50\n",
        "  output_image = cv.resize(output_image, None , fx = rate, fy = rate, interpolation = cv.INTER_NEAREST)\n",
        "  return output_image\n",
        "  #cv2.imwrite('hit-miss.png', output_image) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4xb9WGhQCqE"
      },
      "source": [
        "#dilation part\n",
        "\n",
        "def dilation(img):\n",
        "  # Taking a matrix of size 5 as the kernel \n",
        "    kernel = np.ones((5,5), np.uint8)                                 # parametre\n",
        "\n",
        "  img_dilation = cv2.dilate(img, kernel, iterations=1)                # parametre\n",
        "\n",
        "  return img_dilation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tjr6HnckR6Sv"
      },
      "source": [
        "#erosion part\n",
        "\n",
        "def erosion(img):\n",
        "  # Taking a matrix of size 5 as the kernel \n",
        "  kernel = np.ones((5,5), np.uint8)                                 # parametre\n",
        "\n",
        "  img_erosion = cv2.erosion(img, kernel, iterations=1)              # parametre\n",
        "\n",
        "  return img_erosion"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gMtJQn8SJkg"
      },
      "source": [
        "def opening(img):\n",
        "  # Taking a matrix of size 5 as the kernel \n",
        "  kernel = np.ones((5,5), np.uint8)                                 # parametre\n",
        "\n",
        "  img_erosion = cv2.erosion(img, kernel, iterations=1)              # parametre\n",
        "  img_opening = cv2.dilate(img_erosion, kernel, iterations=1) \n",
        "\n",
        "  return img_opening"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfLGesH1SYop"
      },
      "source": [
        "def closing(img):\n",
        "  # Taking a matrix of size 5 as the kernel \n",
        "  kernel = np.ones((5,5), np.uint8)                                 # parametre\n",
        "\n",
        "  img_dilate = cv2.dilate(img, kernel, iterations=1)              # parametre\n",
        "  img_closing = cv2.erosion(img_dilate, kernel, iterations=1) \n",
        "\n",
        "  return img_closing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daYTxNVXS6tZ"
      },
      "source": [
        "#adaptive thresholding part\n",
        "import cv2 as cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "def closing(img):\n",
        "  img = cv2.medianBlur(img,5)\n",
        "\n",
        "  ret,th1 = cv2.threshold(img,127,255,cv2.THRESH_BINARY)\n",
        "  th2 = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_MEAN_C,\\\n",
        "              cv2.THRESH_BINARY,11,2)\n",
        "  th3 = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
        "              cv2.THRESH_BINARY,11,2)\n",
        "\n",
        "  titles = ['Original Image', 'Global Thresholding (v = 127)',\n",
        "              'Adaptive Mean Thresholding', 'Adaptive Gaussian Thresholding']\n",
        "  return th3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLUSyaz8U9N-"
      },
      "source": [
        "#gamma correction part\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "def adjust_gamma(image, gamma=1.0):\n",
        "\t# build a lookup table mapping the pixel values [0, 255] to\n",
        "\t# their adjusted gamma values\n",
        "\tinvGamma = 1.0 / gamma\n",
        "\ttable = np.array([((i / 255.0) ** invGamma) * 255\n",
        "\t\tfor i in np.arange(0, 256)]).astype(\"uint8\")\n",
        "\t# apply gamma correction using the lookup table\n",
        "\treturn cv2.LUT(image, table)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}